{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manhili/Deep-Learning/blob/main/Train_Test_pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import warnings\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.metrics import jaccard_similarity_score\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "DAT_PATH = 'dataset/'\n",
        "TARGET = 'MAP'\n",
        "\n",
        "random_seed = 42\n",
        "\n",
        "CHANNELS_PATCHGAN = 6\n",
        "\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "n= 800  # NOMBRE D'IMAGES TRAIN + TEST\n",
        "n_split= 0.75 # DIVISION 75% POUR LE TRAIN ET 25% POUR LE TEST\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "S_e_bgtT_DXN"
      },
      "id": "S_e_bgtT_DXN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63fe343f-2975-462e-8cc0-ca1493b3b0bc",
      "metadata": {
        "id": "63fe343f-2975-462e-8cc0-ca1493b3b0bc",
        "outputId": "195310f4-25ae-4d88-fcd2-8da409f0ad97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\manal\\anaconda3\\envs\\gansp3\\lib\\site-packages (from tqdm) (0.4.4)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.62.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#!pip install opencv-python\n",
        "#!pip install Pillow\n",
        "#!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad3c4bf-4fee-44aa-b6a1-7359e0327d6f",
      "metadata": {
        "id": "fad3c4bf-4fee-44aa-b6a1-7359e0327d6f"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf7f9f0-074f-4d5b-b7dc-430ccad6d077",
      "metadata": {
        "id": "abf7f9f0-074f-4d5b-b7dc-430ccad6d077"
      },
      "outputs": [],
      "source": [
        "targets = ['seg','streaks','globules','milia','pigment','negatives']\n",
        "\n",
        "map_targets ={'seg':0,'streaks':1,'globules':2,'milia':3,'pigment':4,'negatives':5}\n",
        "\n",
        "CHANNELS = len(targets)\n",
        "REPATH = 'results/'\n",
        "INPATH = DAT_PATH+'IMAGES/'\n",
        "OUPATH = DAT_PATH+TARGET+'/'\n",
        "REPATHCK = REPATH+'checkpoints_'+TARGET+'/'\n",
        "REPATHOU = REPATH+'output_'+TARGET+'/'\n",
        "#imgurls = os.listdir(INPATH)\n",
        "imgurls = [os.path.splitext(filename)[0] for filename in os.listdir(INPATH)]\n",
        "print(imgurls[:2])\n",
        "imgurls.sort()\n",
        "print(imgurls[:2])\n",
        "\n",
        "jaccard_index_total =[]\n",
        "train_n = round(n*0.75)\n",
        "\n",
        "#liste aléatoire\n",
        "\n",
        "randurls = np.copy(imgurls)\n",
        "\n",
        "np.random.seed(random_seed) # importante \n",
        "np.random.shuffle(randurls)\n",
        "\n",
        "#partition train/test\n",
        "\n",
        "tr_urls = randurls[:train_n]\n",
        "ts_urls = randurls[train_n:n]\n",
        "\n",
        "print(len(imgurls),len(tr_urls),len(ts_urls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29cf7feb-2662-445f-90bc-bd6eb793c851",
      "metadata": {
        "id": "29cf7feb-2662-445f-90bc-bd6eb793c851"
      },
      "outputs": [],
      "source": [
        "n_ = [0,1,2]+[i*BATCH_SIZE for i in [1,2,3]]\n",
        "ts_urls[n_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9ec55b2-fc6c-4be8-ab99-617709581fd0",
      "metadata": {
        "id": "b9ec55b2-fc6c-4be8-ab99-617709581fd0"
      },
      "outputs": [],
      "source": [
        "def create_folder(path,name):\n",
        "    import os\n",
        "    try:\n",
        "        path=path+name\n",
        "        os.mkdir(path)\n",
        "    except OSError:\n",
        "        print (\"Exist or Failed the directory %s\" % path)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a05b76-87a8-4d1f-8a6f-c84004028570",
      "metadata": {
        "id": "b2a05b76-87a8-4d1f-8a6f-c84004028570"
      },
      "outputs": [],
      "source": [
        "create_folder(REPATHOU+'example_images','')\n",
        "create_folder(REPATHOU+'example_maps','')\n",
        "for file_name in ts_urls[n_]:\n",
        "    create_folder(REPATHOU+'example_images/'+file_name,'')\n",
        "    create_folder(REPATHOU+'example_maps/'+file_name,'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec53bcb3-09e2-4864-bc94-7bb79a953443",
      "metadata": {
        "id": "ec53bcb3-09e2-4864-bc94-7bb79a953443"
      },
      "outputs": [],
      "source": [
        "def resize(inimg,tgimg,heigth,width):\n",
        "    \n",
        "    inimg = tf.image.resize(inimg,[heigth,width])\n",
        "    tgimg = tf.image.resize(tgimg,[heigth,width])\n",
        "    \n",
        "    return inimg,tgimg\n",
        "# normaliser les images [-1 +1]\n",
        "\n",
        "def normalize(inimg,tgimg):\n",
        "    \n",
        "    inimg = (inimg/127.5) -1\n",
        "    \n",
        "    tgimg = (tgimg/127.5) -1\n",
        "    \n",
        "    return inimg,tgimg\n",
        "\n",
        "\n",
        "\n",
        "# Augmentation des données : Random Crop + Flip\n",
        "@tf.function()\n",
        "def random_jitter(inimg,tgimg):\n",
        "    inimg , tgimg = resize(inimg,tgimg,IMG_WIDTH,IMG_HEIGHT)\n",
        "    stacked_image = tf.stack([inimg,tgimg],axis=0)\n",
        "    cropped_image = tf.image.random_crop(stacked_image,size=[2,IMG_HEIGHT,IMG_WIDTH,3])\n",
        "    \n",
        "    if( tf.random.uniform(())>0.5):\n",
        "        cropped_image = tf.image.flip_left_right(cropped_image)\n",
        "    inimg,tgimg = cropped_image[0],cropped_image[1]\n",
        "    \n",
        "    return inimg,tgimg\n",
        "\n",
        "def load_images(filename, augment = True):\n",
        "    \n",
        "    inimg =  tf.cast(tf.image.decode_jpeg(tf.io.read_file(INPATH+'/'+filename+'.jpg')),tf.float32)[..., :3]\n",
        "    tgimg1 =  tf.cast(tf.image.decode_jpeg(tf.io.read_file(OUPATH+'/'+filename+'_1.png')),tf.float32)[..., :3]\n",
        "    tgimg2 =  tf.cast(tf.image.decode_jpeg(tf.io.read_file(OUPATH+'/'+filename+'_2.png')),tf.float32)[..., :3]\n",
        "    tgimg = tf.concat([tgimg1, tgimg2],2)\n",
        "    inimg, tgimg = resize(inimg,tgimg,IMG_HEIGHT,IMG_WIDTH)\n",
        "    inimg,tgimg = normalize(inimg,tgimg)\n",
        "\n",
        "    return inimg,tgimg\n",
        "\n",
        "def load_train_images(filename):\n",
        "    return load_images(filename,True)\n",
        "def load_test_images(filename):\n",
        "    return load_images(filename,False)\n",
        "\n",
        "\n",
        "def get_jaccard(epoch):\n",
        "    \n",
        "    mask_original=[]\n",
        "    mask_predict =[]\n",
        "    iou=[]\n",
        "    for i in range(6):\n",
        "        mask_predict.append([])\n",
        "        mask_original.append([])\n",
        "        #iou.apppend([])\n",
        "    #print(n_epoch)\n",
        "    \n",
        "    #REPATHOU+name+save_filename+'_1.png',prediction[idx,:,:,:3])\n",
        "    for idx, filename in enumerate(ts_urls):\n",
        "        \n",
        "        map_image1 = plt.imread(REPATHOU+filename+'_'+str(epoch)+'_1.png')\n",
        "        os.remove(REPATHOU+filename+'_'+str(epoch)+'_1.png')\n",
        "        map_image2 = plt.imread(REPATHOU+filename+'_'+str(epoch)+'_2.png')\n",
        "        os.remove(REPATHOU+filename+'_'+str(epoch)+'_2.png')\n",
        "        map_image =np.concatenate((map_image1, map_image2), axis=2)\n",
        "        \n",
        "        real_image = plt.imread(INPATH+'/'+filename+'.jpg')\n",
        "        map_image_real1 = plt.imread(OUPATH+'/'+filename+'_1.png')\n",
        "        map_image_real2 = plt.imread(OUPATH+'/'+filename+'_2.png')\n",
        "        map_image_real =np.concatenate((map_image_real1, map_image_real2), axis=2)\n",
        "        \n",
        "        for j in range(CHANNELS):\n",
        "            mask_predict[j].append(map_image[:,:,j]>0)\n",
        "            mask_original[j].append(map_image_real[:,:,j]>0)\n",
        "\n",
        "\n",
        "        if(idx<3):\n",
        "\n",
        "            plt.figure(figsize=(60,8.5))\n",
        "            \n",
        "            display_list = [real_image,map_image_real1,map_image_real2,map_image1,map_image2]\n",
        "\n",
        "            title = ['Real']+['Test Truth_'+str(f) for f in range(CHANNELS//3)]+['Test gen _'+str(f) for f in range(CHANNELS//3) ]\n",
        "            title = [filename]+['Ground Truth_'+str(f) for f in range(CHANNELS//3)]+['Predicted Image_'+str(f) for f in range(CHANNELS//3) ]\n",
        "            \n",
        "            for i in range(len(display_list)):\n",
        "                plt.subplot(1,len(display_list),i+1)\n",
        "                plt.title(title[i], fontsize=40)\n",
        "                # de -1 1 -->  a 0 1\n",
        "                plt.imshow(display_list[i])\n",
        "                plt.axis('off')\n",
        "                \n",
        "            plt.savefig(REPATHOU+'example_images/'+filename+'/'+filename+'_'+str(epoch))\n",
        "            plt.show()\n",
        "\n",
        "    for j in range(6):\n",
        "        img_true=np.array(mask_original[j]).ravel()\n",
        "        img_pred=np.array(mask_predict[j]).ravel()\n",
        "        iou.append(jaccard_similarity_score(img_true, img_pred))\n",
        "    #print(TARGET +': jaccard index  = ',iou)\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfe1349-f447-467b-9fed-9a8b441237a5",
      "metadata": {
        "id": "edfe1349-f447-467b-9fed-9a8b441237a5"
      },
      "outputs": [],
      "source": [
        "tf.__version__  # you should get 2.0.0-rc0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1aaba35-c6e2-47ee-a761-b20d10a5f888",
      "metadata": {
        "id": "b1aaba35-c6e2-47ee-a761-b20d10a5f888"
      },
      "outputs": [],
      "source": [
        "for idx in [3]:\n",
        "\n",
        "    melanoma =load_train_images(randurls[idx])\n",
        "\n",
        "    fig, axs = plt.subplots(1, CHANNELS+1, figsize=(60,8.5), sharey=True)\n",
        "    axs[0].imshow((melanoma[0]+1)/2.0)\n",
        "    axs[0].set_title('Image', fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "    for i in range(CHANNELS):\n",
        "        axs[i+1].imshow((melanoma[1][:,:,map_targets[targets[i]]]+1)/2.0)\n",
        "        axs[i+1].set_title(targets[i], fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "    fig.suptitle('Example of training dataset', fontsize=40)\n",
        "    plt.savefig('images/'+TARGET+'_EXAMPLE_'+randurls[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a902d5cf-3d45-4821-9f3e-f0242b4c9460",
      "metadata": {
        "id": "a902d5cf-3d45-4821-9f3e-f0242b4c9460"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(tr_urls)\n",
        "train_dataset =  train_dataset.map(load_train_images,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(ts_urls)\n",
        "test_dataset =  test_dataset.map(load_test_images,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0c4516-0616-41a1-b1f4-2dac5d6e7466",
      "metadata": {
        "id": "ea0c4516-0616-41a1-b1f4-2dac5d6e7466"
      },
      "outputs": [],
      "source": [
        "for inimg,tgimg in test_dataset.take(1):\n",
        "    fig, axs = plt.subplots(1, CHANNELS+1, figsize=(60,8.5), sharey=True)\n",
        "    axs[0].imshow((inimg[0]+1)/2.0)\n",
        "    axs[0].set_title('Image', fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "    for i in range(CHANNELS):\n",
        "        axs[i+1].imshow((tgimg[0][:,:,map_targets[targets[i]]]+1)/2.0)\n",
        "        axs[i+1].set_title(targets[i], fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "fig.suptitle('Example of testing dataset', fontsize=40)\n",
        "plt.savefig('images/'+TARGET+'_EXAMPLE_'+ts_urls[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d6b8a4-bc92-42b5-8849-26cc5ea9e171",
      "metadata": {
        "id": "b1d6b8a4-bc92-42b5-8849-26cc5ea9e171"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import *\n",
        "def downsample(filters,apply_batchnorm=True):\n",
        "     \n",
        "    result = Sequential()\n",
        "    \n",
        "    initializer = tf.random_normal_initializer(0,0.02)\n",
        "    \n",
        "    # CApa de convolucion\n",
        "    result.add(Conv2D(filters,\n",
        "                      kernel_size=4,\n",
        "                     strides =2,\n",
        "                     padding ='same',\n",
        "                     kernel_initializer=initializer,\n",
        "                     use_bias=not apply_batchnorm))\n",
        "    \n",
        "    if apply_batchnorm:\n",
        "        # CApa de batchnormalization\n",
        "        result.add(BatchNormalization())\n",
        "\n",
        "    # CApa de activación\n",
        "    result.add(LeakyReLU())\n",
        "    \n",
        "    return result\n",
        "\n",
        "downsample(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df31e35-24f0-4def-b3ee-bc3cf861d81f",
      "metadata": {
        "id": "6df31e35-24f0-4def-b3ee-bc3cf861d81f"
      },
      "outputs": [],
      "source": [
        "def upsample(filters,apply_dropout=False):\n",
        "     \n",
        "    result = Sequential()\n",
        "    \n",
        "    initializer = tf.random_normal_initializer(0,0.02)\n",
        "    \n",
        "    # Capa de convolucion\n",
        "    result.add(Conv2DTranspose(filters,\n",
        "                              kernel_size=4,\n",
        "                             strides =2,\n",
        "                             padding ='same',\n",
        "                             kernel_initializer=initializer,\n",
        "                             use_bias=False))\n",
        "\n",
        "    # Capa de batchnormalization\n",
        "    result.add(BatchNormalization())\n",
        "    \n",
        "    if apply_dropout:\n",
        "        # Capa de dropout\n",
        "        result.add(Dropout(0.5))\n",
        "        \n",
        "    # Capa de activación\n",
        "    result.add(ReLU())\n",
        "    \n",
        "    return result\n",
        "upsample(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed9a7a78-b5e2-490b-b0dc-a3384e4b4cdb",
      "metadata": {
        "id": "ed9a7a78-b5e2-490b-b0dc-a3384e4b4cdb"
      },
      "outputs": [],
      "source": [
        "def Generator ():\n",
        "    \n",
        "    initializer = tf.random_normal_initializer(0,0.02)\n",
        "\n",
        "    inputs =tf.keras.layers.Input(shape = [None,None,3])\n",
        "    \n",
        "    down_stack = [\n",
        "                                                            #64 filtres --> 64 cartes de caractéristiques\n",
        "        downsample(64,apply_batchnorm=False),  # (bs,128,128,64)  la normalisation des lots ne sera pas appliquée \n",
        "        downsample(128),                       # (bs,64,64,128) \n",
        "        downsample(256),                       # (bs,32,32,256)\n",
        "        downsample(512),                       # (bs,16,16,512)\n",
        "        downsample(512),                       # (bs,8,8,512)\n",
        "        downsample(512),                       # (bs,4,4,512)\n",
        "        downsample(512),                       # (bs,2,2,512)\n",
        "        downsample(512),                       # (bs,1,1,512)\n",
        "    ]\n",
        "    \n",
        "    up_stack = [\n",
        "        \n",
        "        upsample(512,apply_dropout=True),       # (bs,2,2,1024)\n",
        "        upsample(512,apply_dropout=True),       # (bs,4,4,1024)\n",
        "        upsample(512,apply_dropout=True),       # (bs,8,8,1024)\n",
        "        upsample(512),                          # (bs,16,16,1024)\n",
        "        upsample(256),                          # (bs,32,32,512)  # Aucun dropout ne sera appliqué \n",
        "        upsample(128),                          # (bs,64,64,256)\n",
        "        upsample(64),                           # (bs,128,128,128)\n",
        "        \n",
        "    ]\n",
        "    \n",
        "    last = Conv2DTranspose(filters= CHANNELS, # vamos a generar una imagen de n = CHANNELS\n",
        "                           kernel_size=4,\n",
        "                           strides = 2,\n",
        "                           padding = 'same',\n",
        "                           kernel_initializer = initializer,\n",
        "                           activation = 'tanh' # porque nuestras imagenes de salida son de (-1 a 1)\n",
        "                          )\n",
        "    x= inputs\n",
        "    \n",
        "    s =  []  # lista de skip connections\n",
        "    \n",
        "    concat = Concatenate()\n",
        "    \n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        s.append(x)\n",
        "    \n",
        "    s = reversed(s[:-1]) # no se toma el ultimo valor por ser un cuello de botella\n",
        "    \n",
        "    for up,sk in zip(up_stack,s):\n",
        "        \n",
        "        x = up(x)\n",
        "        x = concat([x,sk])\n",
        "        \n",
        "    last = last(x)\n",
        "    \n",
        "    return Model(inputs=inputs,outputs=last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c466e859-3b0a-4dac-a08e-13f73d1d182d",
      "metadata": {
        "id": "c466e859-3b0a-4dac-a08e-13f73d1d182d"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "gen_output = generator(((tf.reshape(inimg[3],(1,IMG_WIDTH,IMG_HEIGHT,3)))), training = False)\n",
        "#plt.imshow(gen_output[0,:,:,:3])\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, CHANNELS+1,  figsize=(60,8.5), sharey=True)\n",
        "axs[0].imshow((inimg[0]+1)/2.0)\n",
        "axs[0].set_title('Image', fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "for i in range(CHANNELS):\n",
        "    axs[i+1].imshow((gen_output[0][:,:,map_targets[targets[i]]]+1)/2.0)\n",
        "    axs[i+1].set_title('new '+targets[i], fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "fig.suptitle('Example of generator', fontsize=40)\n",
        "plt.savefig('images/'+TARGET+'_EXAMPLE_GENERATOR_'+randurls[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5478ac41-0bed-41fc-9e07-ec1baf123316",
      "metadata": {
        "id": "5478ac41-0bed-41fc-9e07-ec1baf123316"
      },
      "outputs": [],
      "source": [
        "def Discriminator():\n",
        "    \n",
        "    ini = Input(shape = [None,None,3], name = \"input_img\")\n",
        "    gen = Input(shape = [None,None,6], name = \"gener_img\")\n",
        "\n",
        "    con = concatenate([ini,gen])  # [256,256,3]\n",
        "    \n",
        "    initializer = tf.random_normal_initializer(0,0.02)\n",
        "    \n",
        "    down1 = downsample(64, apply_batchnorm=False)(con)\n",
        "    down2 = downsample(128)(down1)\n",
        "    down3 = downsample(216)(down2)\n",
        "    down4 = downsample(512)(down3)\n",
        "    \n",
        "    last = tf.keras.layers.Conv2D(filters=CHANNELS_PATCHGAN,\n",
        "                                 kernel_size=4,\n",
        "                                 strides=1,\n",
        "                                 kernel_initializer=initializer,\n",
        "                                 padding = 'same')(down4)  # salida un unico canal que indica si es real o no\n",
        "    \n",
        "    return tf.keras.Model(inputs = [ini,gen],outputs = last)\n",
        "\n",
        "discriminator = Discriminator()\n",
        "disc_output = discriminator(([(tf.reshape(inimg[0],(1,IMG_WIDTH,IMG_HEIGHT,3))+1)*255,gen_output]), training = False)\n",
        "\n",
        "plt.figure(figsize=(60,8.5))\n",
        "plt.suptitle('Example of discriminator', fontsize=40)\n",
        "\n",
        "for i in range(CHANNELS):\n",
        "    plt.subplot(1, CHANNELS+1,i+1)\n",
        "    plt.imshow((tgimg[0][:,:,map_targets[targets[i]]]+1)/2.0)\n",
        "    plt.gca().set_title('real '+targets[i], fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "    \n",
        "plt.subplot(1,CHANNELS+1,CHANNELS+1)\n",
        "plt.imshow(disc_output[0,...,-1],vmin=-20,vmax=20,cmap='RdBu_r')\n",
        "plt.gca().set_title('real or not', fontdict={'fontsize': 40, 'fontweight': 'medium'})\n",
        "plt.savefig('images/'+TARGET+'_EXAMPLE_DISCRIMINATOR_'+ts_urls[0])\n",
        "plt.show()\n",
        "\n",
        "disc_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb820944-8529-42af-8bb0-aa355fe72c1b",
      "metadata": {
        "id": "cb820944-8529-42af-8bb0-aa355fe72c1b"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True) # from_logits para aplicar la funcion sigmoide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4690f0b0-a68c-468c-a5e4-a659303d1f07",
      "metadata": {
        "id": "4690f0b0-a68c-468c-a5e4-a659303d1f07"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    \n",
        "    # Diferencia entre los true por ser real y el detectado por el discriminador\n",
        "    # lo idoneo seria obtener todo 1 que indica que todas las areas son reales\n",
        "    real_loss = loss_object(tf.ones_like(disc_real_output),disc_real_output)\n",
        "    \n",
        "    # Diferencia entre los false por ser generado y el detectado por el discriminador\n",
        "    generated_loss = loss_object(tf.zeros_like(disc_generated_output),disc_generated_output)\n",
        "    \n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "    \n",
        "    return total_disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c0bba72-5a39-4e53-8a1a-c034b4024c0d",
      "metadata": {
        "id": "9c0bba72-5a39-4e53-8a1a-c034b4024c0d"
      },
      "outputs": [],
      "source": [
        "LAMBDA = 100\n",
        "\n",
        "# the map generated by the discriminator , the image generated by the generator and the real image \n",
        "def generator_loss(disc_generator_output, gen_output, target):\n",
        "    \n",
        "    # Difference between the false to be generated and the false detected by the discriminator\n",
        "    gan_loss = loss_object(tf.ones_like(disc_generator_output),disc_generator_output)\n",
        "    \n",
        "    # mean absolute error\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target-gen_output))\n",
        "    \n",
        "    total_gen_loss = gan_loss +(LAMBDA*l1_loss)\n",
        "    return total_gen_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dbd733b-28e3-4598-8858-9754aa3356d0",
      "metadata": {
        "id": "8dbd733b-28e3-4598-8858-9754aa3356d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "generator_optimizer  = tf.keras.optimizers.Adam(2e-4, beta_1= 0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1= 0.5)\n",
        "\n",
        "checkpoint_prefix = os.path.join(REPATHCK,'ckpt')\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator = discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a4bc2c-47ef-4c69-986a-bec9c2e49de9",
      "metadata": {
        "id": "50a4bc2c-47ef-4c69-986a-bec9c2e49de9"
      },
      "outputs": [],
      "source": [
        "def generate_images(epoch,model,test_input,tar,imgi,display_imgs=True):\n",
        "    prediction = model(test_input, training = True)\n",
        "    save_filenames = ts_urls[imgi*BATCH_SIZE:(imgi+1)*BATCH_SIZE]\n",
        "    \n",
        "    for idx,name in enumerate(save_filenames):\n",
        "        tf.keras.preprocessing.image.save_img(REPATHOU+name+'_'+str(epoch)+'_1.png',prediction[idx,:,:,:3])\n",
        "        tf.keras.preprocessing.image.save_img(REPATHOU+name+'_'+str(epoch)+'_2.png',prediction[idx,:,:,3:])\n",
        "    \n",
        "    if(imgi==0):\n",
        "        for idy in [0,1,2]:\n",
        "            for idx in range(CHANNELS):\n",
        "                tf.keras.preprocessing.image.save_img(REPATHOU+'example_maps/'+save_filenames[idy]+'/'+save_filenames[idy]+'_'+str(epoch)+'_1.png',prediction[idy,:,:,:3])\n",
        "                tf.keras.preprocessing.image.save_img(REPATHOU+'example_maps/'+save_filenames[idy]+'/'+save_filenames[idy]+'_'+str(epoch)+'_2.png',prediction[idy,:,:,3:])\n",
        "        \n",
        "    if(imgi>0 and imgi<4):\n",
        "        plt.figure(figsize=(60,8.5))\n",
        "        display_list = [test_input[0], tar[0,:,:,:3],tar[0,:,:,3:], prediction[0,:,:,:3],prediction[0,:,:,3:]]\n",
        "        title = [save_filenames[0]]+['Ground Truth_'+str(f) for f in range(CHANNELS//3)]+['Predicted Image_'+str(f) for f in range(CHANNELS//3) ]\n",
        "        for idx in range(CHANNELS):\n",
        "            tf.keras.preprocessing.image.save_img(REPATHOU+'example_maps/'+save_filenames[0]+'/'+save_filenames[0]+'_'+str(epoch)+'_1.png',prediction[0,:,:,:3])\n",
        "            tf.keras.preprocessing.image.save_img(REPATHOU+'example_maps/'+save_filenames[0]+'/'+save_filenames[0]+'_'+str(epoch)+'_2.png',prediction[0,:,:,3:])\n",
        "\n",
        "\n",
        "        if display_imgs:\n",
        "            for i in range(len(display_list)):\n",
        "                plt.subplot(1,len(display_list),i+1)\n",
        "                plt.title(title[i], fontsize=40)\n",
        "                # de -1 1 -->  a 0 1\n",
        "                plt.imshow(display_list[i]*0.5+0.5)\n",
        "                plt.axis('off')\n",
        "                \n",
        "        plt.savefig(REPATHOU+'example_images/'+save_filenames[0]+'/'+save_filenames[0]+'_'+str(epoch))\n",
        "        plt.show()\n",
        "    return prediction.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbba25d-a970-4f78-a42f-c10370e92563",
      "metadata": {
        "id": "4bbba25d-a970-4f78-a42f-c10370e92563"
      },
      "outputs": [],
      "source": [
        "for i,j in enumerate(range(3,5)):\n",
        "    print(i,j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28089a36-ee69-4942-ac9b-e48ec206d39a",
      "metadata": {
        "id": "28089a36-ee69-4942-ac9b-e48ec206d39a"
      },
      "outputs": [],
      "source": [
        "@tf.function()\n",
        "def train_step(input_image,target):\n",
        "    \n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as discr_tape:\n",
        "        output_image = generator(input_image, training = True)\n",
        "\n",
        "        output_gen_discr =  discriminator([input_image,output_image],training = True)\n",
        "\n",
        "        output_trg_discr =  discriminator([input_image,target],training = True)\n",
        "\n",
        "        discr_loss = discriminator_loss(output_trg_discr, output_gen_discr)\n",
        "\n",
        "        gen_loss =  generator_loss(output_gen_discr,output_image,target)\n",
        "    \n",
        "        generator_grads =  gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        \n",
        "        discriminator_grads = discr_tape.gradient(discr_loss, discriminator.trainable_variables)\n",
        "        \n",
        "        generator_optimizer.apply_gradients(zip(generator_grads,generator.trainable_variables))\n",
        "        \n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_grads,discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111eafa6-6fb7-4442-a490-7be80230d44a",
      "metadata": {
        "id": "111eafa6-6fb7-4442-a490-7be80230d44a"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        imgi=0\n",
        "        \n",
        "        for input_image,target in dataset:\n",
        "            print('epoch '+str(epoch)+' - train: '+str(imgi)+'/'+ str(len(tr_urls)//BATCH_SIZE))\n",
        "            imgi+=1\n",
        "            train_step(input_image,target)\n",
        "            clear_output(wait=True)\n",
        "\n",
        "        imgi=0\n",
        "        predictions = []\n",
        "        for inp, tar in test_dataset:\n",
        "            #print('before',imgi)\n",
        "            generate_images(epoch,generator, inp, tar,imgi, display_imgs = True)\n",
        "            imgi+=1\n",
        "        jaccard_index_total.append(get_jaccard(epoch))\n",
        "        if (epoch +1)% 25 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409800f8-88c5-4053-ba0b-ec3cdd45f968",
      "metadata": {
        "id": "409800f8-88c5-4053-ba0b-ec3cdd45f968"
      },
      "outputs": [],
      "source": [
        "for a,b in test_dataset:\n",
        "    print(a.shape,b.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62a027a-b2b0-41c0-b377-e79881edc091",
      "metadata": {
        "id": "b62a027a-b2b0-41c0-b377-e79881edc091"
      },
      "outputs": [],
      "source": [
        "train(train_dataset,n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebfdc6fa-4a5f-493e-9e0f-cdfd7cd5fff2",
      "metadata": {
        "id": "ebfdc6fa-4a5f-493e-9e0f-cdfd7cd5fff2"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [60,8.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744c2d67-4740-42ad-b37d-8d16c64e2be9",
      "metadata": {
        "id": "744c2d67-4740-42ad-b37d-8d16c64e2be9"
      },
      "outputs": [],
      "source": [
        "jaccard_index_total_aux = jaccard_index_total.copy()\n",
        "np.save('jaccard_index_PATCHGAN'+str(CHANNELS_PATCHGAN)+'_'+str(BATCH_SIZE)+'_'+str(n)+'_XD.npy',jaccard_index_total_aux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bafcbbf-29ba-46a4-817c-3a2d7715acdd",
      "metadata": {
        "id": "0bafcbbf-29ba-46a4-817c-3a2d7715acdd"
      },
      "outputs": [],
      "source": [
        "jaccard_index_total = np.load('jaccard_index_PATCHGAN'+str(CHANNELS_PATCHGAN)+'_'+str(BATCH_SIZE)+'_'+str(n)+'_XD.npy')\n",
        "\n",
        "jaccard_atribute = []\n",
        "for i in range(CHANNELS):\n",
        "    jaccard_atribute.append([])\n",
        "for jaccard_by_epoch in jaccard_index_total:\n",
        "    for j in range(CHANNELS):\n",
        "        jaccard_atribute[j].append(jaccard_by_epoch[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7a10988-a1f6-4b3c-b38f-95f10e237aaf",
      "metadata": {
        "id": "a7a10988-a1f6-4b3c-b38f-95f10e237aaf"
      },
      "outputs": [],
      "source": [
        "for idx,jaccard_idx in enumerate(jaccard_atribute):\n",
        "    fig = plt.figure(figsize=(50,20))\n",
        "    n_epochs = 100\n",
        "    jaccard_idx = jaccard_idx[0:100]\n",
        "    plt.scatter(range(0,n_epochs),jaccard_idx)\n",
        "    #z = np.polyfit(range(0,n_epochs), np.log(jaccard_idx),1)\n",
        "    #p = np.poly1d(z)\n",
        "    #plt.plot(range(0,n_epochs),np.exp(p(range(0,n_epochs))),\"r--\")\n",
        "    \n",
        "    from scipy.ndimage.filters import gaussian_filter1d\n",
        "    ysmoothed = gaussian_filter1d(jaccard_idx, sigma=2)\n",
        "    plt.plot(range(0,n_epochs),ysmoothed,\"r--\")\n",
        "\n",
        "    \n",
        "    #fig.suptitle(targets[idx], fontsize=20)\n",
        "    plt.xlabel('epochs', fontsize=40)\n",
        "    plt.ylabel('jaccard index', fontsize=40)\n",
        "    maxi = str(round(np.max(jaccard_idx),5))\n",
        "    plt.legend(['max: '+maxi],fontsize=40)\n",
        "    plt.title(targets[idx], fontsize=40)\n",
        "    plt.show()\n",
        "    fig.savefig(REPATH+TARGET+'_jaccard_'+targets[idx]+'.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab9856e-846e-4675-b4dc-e8a38ebc1b51",
      "metadata": {
        "id": "aab9856e-846e-4675-b4dc-e8a38ebc1b51"
      },
      "outputs": [],
      "source": [
        "jaccard_index_total = np.load('jaccard_index_PATCHGAN'+str(1)+'_'+str(BATCH_SIZE)+'_'+str(n)+'_XD.npy')\n",
        "\n",
        "jaccard_atribute_1 = []\n",
        "for i in range(CHANNELS):\n",
        "    jaccard_atribute_1.append([])\n",
        "for jaccard_by_epoch in jaccard_index_total:\n",
        "    for j in range(CHANNELS):\n",
        "        jaccard_atribute_1[j].append(jaccard_by_epoch[j])\n",
        "jaccard_index_total = np.load('jaccard_index_PATCHGAN'+str(6)+'_'+str(BATCH_SIZE)+'_'+str(n)+'_XD.npy')\n",
        "\n",
        "jaccard_atribute_2 = []\n",
        "for i in range(CHANNELS):\n",
        "    jaccard_atribute_2.append([])\n",
        "for jaccard_by_epoch in jaccard_index_total:\n",
        "    for j in range(CHANNELS):\n",
        "        jaccard_atribute_2[j].append(jaccard_by_epoch[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d041cc9a-6080-46d4-899e-40663f6df640",
      "metadata": {
        "id": "d041cc9a-6080-46d4-899e-40663f6df640"
      },
      "outputs": [],
      "source": [
        "for idx,jaccard_idx in enumerate(jaccard_atribute_1):\n",
        "    fig = plt.figure(figsize=(50,20))\n",
        "    n_epochs = 100\n",
        "    jaccard_idx = jaccard_idx[0:100]\n",
        "    plt.scatter(range(0,n_epochs),jaccard_atribute_1[idx])\n",
        "    from scipy.ndimage.filters import gaussian_filter1d\n",
        "    ysmoothed = gaussian_filter1d(jaccard_idx, sigma=2)\n",
        "    plt.plot(range(0,n_epochs),ysmoothed,\"b--\",linewidth=6, markersize=12)\n",
        "    jaccard_idx = jaccard_atribute_2[idx]\n",
        "    plt.scatter(range(0,n_epochs),jaccard_atribute_2[idx])\n",
        "\n",
        "    #z = np.polyfit(range(0,n_epochs), np.log(jaccard_idx),1)\n",
        "    #p = np.poly1d(z)\n",
        "    #plt.plot(range(0,n_epochs),np.exp(p(range(0,n_epochs))),\"r--\")\n",
        "    \n",
        "    from scipy.ndimage.filters import gaussian_filter1d\n",
        "    ysmoothed = gaussian_filter1d(jaccard_idx, sigma=2)\n",
        "    plt.plot(range(0,n_epochs),ysmoothed,\"r--\",linewidth=6, markersize=12)\n",
        "\n",
        "    \n",
        "    #fig.suptitle(targets[idx], fontsize=20)\n",
        "    plt.xlabel('epochs', fontsize=60)\n",
        "    plt.ylabel('jaccard index', fontsize=60)\n",
        "    maxi_1 = str(round(np.max(jaccard_atribute_1[idx]),3))\n",
        "    maxi_2 = str(round(np.max(jaccard_atribute_2[idx]),3))\n",
        "    plt.legend(['1 channel   - max: '+maxi_1,'6 channels - max: '+maxi_2],fontsize=60)\n",
        "    plt.title(targets[idx], fontsize=60)\n",
        "    plt.show()\n",
        "    fig.savefig(REPATH+TARGET+'_jaccard_COMPARATION_1_TO_6'+targets[idx]+'.jpg')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Train_Test_pix2pix.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}